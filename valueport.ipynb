{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dafbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from vnstock import Quote\n",
    "from vnstock import Finance\n",
    "from scipy import stats\n",
    "import time\n",
    "from typing import Literal\n",
    "from scipy.interpolate import interp1d\n",
    "from pyvinecopulib import Bicop, FitControlsBicop\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e85f0",
   "metadata": {},
   "source": [
    "<h1>I. Thu thap du lieu<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c01692",
   "metadata": {},
   "source": [
    "<h2>1. Xac dinh cong ty can de tam<h2>\n",
    "<h3>Phan nay khong can chay lai nua<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tim ma chung khoan cua cac cong ty\n",
    "symbol = pd.read_csv('Du lieu.csv')\n",
    "symbol.columns = symbol.iloc[0]\n",
    "symbol = symbol.iloc[1::]\n",
    "interest_industry = list(symbol['Lĩnh vực'].unique())\n",
    "interest_industry.pop(1)\n",
    "symbol = symbol[symbol['Lĩnh vực'].isin(interest_industry)]\n",
    "symbol_name = list(symbol['Công ty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50deb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phan chia so lan lay du lieu\n",
    "STT_list = [0,55,110,156]\n",
    "name_bins = {}\n",
    "for i in range(len(STT_list)):\n",
    "    if STT_list[i] == 0:\n",
    "        continue\n",
    "    else:\n",
    "        name_bins[STT_list[i]] = symbol_name[STT_list[i-1]:STT_list[i]]\n",
    "history_price = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thu thap du lieu ve gia\n",
    "#Khong can chay o du lieu nay\n",
    "for i in name_bins[156]:\n",
    "    pr = Quote(source='VCI',symbol=i)\n",
    "    price_status = pr.history(start='2010-01-01',end='2025-01-01',interval='1M')\n",
    "    price_status['time'] = pd.to_datetime(price_status['time'])\n",
    "    price_status.set_index('time', inplace=True)\n",
    "    history_price[i] = price_status['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d3494",
   "metadata": {},
   "source": [
    "<h2>2. Chon loc ra cac co phieu trong so 200 cp co gia tri von hoa lon nhat<h2>\n",
    "<h3>Phan nay khong can chay lai nua<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chia co phieu ra lam 2 thoi ky\n",
    "history_price = pd.read_csv('price data.csv')\n",
    "history_price['time'] = pd.to_datetime(history_price['time'])\n",
    "history_price.set_index('time', inplace=True)\n",
    "history_price = history_price[history_price.index.year>2015]\n",
    "history_price.dropna(axis=1,inplace=True)\n",
    "history_price.to_csv('compare_period1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f69fc",
   "metadata": {},
   "source": [
    "<h2>3. Tai du lieu BCTC ve<h2>\n",
    "<h3>Phan nay khong can chay lai nua<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c58e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cac co phieu can lay bao cao tai chinh\n",
    "data = pd.read_csv('compare_period1.csv')\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "data.set_index('time',inplace=True)\n",
    "stock_of_interest = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chia ra thanh cac muc nho hon de lay du lieu\n",
    "count = 0\n",
    "stock_trench = {}\n",
    "number_stock_per_trench = 7\n",
    "number_of_trench = int(round(len(stock_of_interest)/number_stock_per_trench,0)+1)\n",
    "separate_support = [min(number_stock_per_trench*i, len(stock_of_interest)) for i in range(number_of_trench)]#cu chon  co phieu 1 danh sach\n",
    "for i in range(1,len(separate_support)):\n",
    "    stock_trench[separate_support[i]] = stock_of_interest[separate_support[i-1]:separate_support[i]]\n",
    "financial_statement_data = pd.DataFrame()#phuc vu cho cell ke tiep\n",
    "stock_trench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93469a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_cf = ['Năm', 'Kỳ','Khấu hao TSCĐ',\n",
    "           'Mua sắm TSCĐ','Tiền thu được từ thanh lý tài sản cố định'  ]\n",
    "char_is = ['Năm', 'Kỳ','Doanh thu thuần','Thu nhập tài chính','Thu nhập khác','LN trước thuế','Chi phí tiền lãi vay']\n",
    "char_bs = ['Năm', 'Kỳ','TÀI SẢN NGẮN HẠN (đồng)','Tiền và tương đương tiền (đồng)', 'Giá trị thuần đầu tư ngắn hạn (đồng)','Nợ ngắn hạn (đồng)',\n",
    "           'Vay và nợ thuê tài chính ngắn hạn (đồng)',\n",
    "           'Vay và nợ thuê tài chính dài hạn (đồng)',\n",
    "           'TỔNG CỘNG TÀI SẢN (đồng)','VỐN CHỦ SỞ HỮU (đồng)','LỢI ÍCH CỦA CỔ ĐÔNG THIỂU SỐ']\n",
    "char_ratio = ['Năm', 'Kỳ','Số CP lưu hành (Triệu CP)']\n",
    "sleep_time = 40\n",
    "for t in list(stock_trench.keys())[-2::]:\n",
    "    for i in stock_trench[t]:\n",
    "        if i == \"DPP\":\n",
    "            continue\n",
    "        else:\n",
    "            finance = Finance(source='VCI',symbol=i)\n",
    "            #bao cao ket qua hoat dong kinh doanh\n",
    "            income_state = finance.income_statement(lang='vi')\n",
    "            for j in char_is:\n",
    "                if j not in income_state.columns:\n",
    "                    income_state[j]=0\n",
    "            income_state = income_state[char_is]\n",
    "            income_state = income_state[income_state['Năm']>2012]\n",
    "            year = list(income_state['Năm'])\n",
    "            quarter = list(income_state['Kỳ'])\n",
    "            time1 = [f'{i}Q{j}' for i,j in zip(year,quarter)]\n",
    "            time1 = pd.PeriodIndex(time1,freq='Q').to_timestamp(how='end').normalize()\n",
    "            income_state['time'] = time1\n",
    "            income_state.set_index('time',inplace=True)\n",
    "            income_state.drop(['Năm','Kỳ'],axis=1, inplace=True)\n",
    "            #bang can doi ke toan\n",
    "            balance_sheet = finance.balance_sheet(lang='vi')\n",
    "            for j in char_bs:\n",
    "                if j not in balance_sheet.columns:\n",
    "                    balance_sheet[j]=0\n",
    "            balance_sheet = balance_sheet[char_bs]\n",
    "            balance_sheet = balance_sheet[balance_sheet['Năm']>2012]\n",
    "            balance_sheet['time'] = time1\n",
    "            balance_sheet.drop(['Năm','Kỳ'],axis=1, inplace=True)\n",
    "            balance_sheet.set_index('time', inplace=True)\n",
    "            #bao cao luu chuyen tien te\n",
    "            cashflow = finance.cash_flow(lang='vi')\n",
    "            for j in char_cf:\n",
    "                if j not in cashflow.columns:\n",
    "                    cashflow[j] = 0\n",
    "            cashflow = cashflow[char_cf]\n",
    "            cashflow = cashflow[cashflow['Năm']>2012]\n",
    "            cashflow['time'] = time1\n",
    "            cashflow.set_index('time', inplace=True)\n",
    "            cashflow.drop(['Năm','Kỳ'],axis=1, inplace=True)\n",
    "            #so luong co phieu dang luu hanh\n",
    "            outstanding_share = finance.ratio(lang='vi')\n",
    "            outstanding_share = outstanding_share.droplevel(level=0,axis=1)\n",
    "            for j in char_ratio:\n",
    "                if j not in outstanding_share.columns:\n",
    "                    outstanding_share[j] = 0\n",
    "            outstanding_share = outstanding_share[char_ratio]\n",
    "            outstanding_share = outstanding_share[outstanding_share['Năm']>2012]\n",
    "            outstanding_share['time']=time1\n",
    "            outstanding_share.set_index('time',inplace=True)\n",
    "            outstanding_share.drop(['Năm','Kỳ'],axis=1, inplace=True)\n",
    "            #sap nhap cac bao cao lai thanh 1 dataframe\n",
    "            financial_statement_subdata = pd.concat([income_state,balance_sheet,cashflow,outstanding_share], axis=1)\n",
    "            financial_statement_subdata['ticket'] = i\n",
    "            #sap nhap cac cong ty lai thanh 1\n",
    "            if len(financial_statement_data) == 0:\n",
    "                financial_statement_data = financial_statement_subdata\n",
    "            else:\n",
    "                financial_statement_data = pd.concat([financial_statement_data,financial_statement_subdata],axis=0)\n",
    "    time.sleep(sleep_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295f73e",
   "metadata": {},
   "source": [
    "<h2>4. Xac nhan lai cac cong ty can de tam, dong thoi thu thap du lieu gia<h2>\n",
    "<h3>Phan nay khong can chay lai nua<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94678bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lay du lieu\n",
    "financial_statement_data = pd.read_csv('financial_statements.csv')\n",
    "financial_statement_data['time'] = pd.to_datetime(financial_statement_data['time'])\n",
    "financial_statement_data.set_index(['ticket','time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phan trench de lay du lieu\n",
    "stock_of_interest = list(financial_statement_data.index.get_level_values(0).unique())\n",
    "stock_trench = {}\n",
    "number_stock_per_trench = 20\n",
    "number_of_trench = int(round(len(stock_of_interest)/number_stock_per_trench,0)+1)\n",
    "trench = [min(number_stock_per_trench*i,len(stock_of_interest)) for i in range(number_of_trench)]\n",
    "l=0\n",
    "for i in range(1,len(trench)):\n",
    "    stock_trench[trench[i]] = stock_of_interest[trench[i-1]:trench[i]]\n",
    "    l += len(stock_of_interest[trench[i-1]:trench[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.DataFrame()\n",
    "compare_data = pd.DataFrame()\n",
    "for t in stock_trench.keys():\n",
    "    for i in stock_trench[t]:\n",
    "        his = Quote(source='VCI', symbol=i)\n",
    "        #du lieu dau vao\n",
    "        input_subdata = his.history(start='2015-01-01',end='2026-01-01',interval='1M')\n",
    "        input_subdata['time'] = pd.to_datetime(input_subdata['time'])\n",
    "        input_subdata.set_index('time',inplace=True)\n",
    "        input_subdata = input_subdata[['close']]\n",
    "        input_subdata.columns = [i]\n",
    "        #Du lieu so sanh\n",
    "        compare_subdata = his.history(start='2020-01-01',end='2026-01-01',interval='1D')\n",
    "        compare_subdata['time'] = pd.to_datetime(compare_subdata['time'])\n",
    "        compare_subdata.set_index('time',inplace=True)\n",
    "        compare_subdata = compare_subdata[['close']]\n",
    "        compare_subdata.columns = [i]\n",
    "        if len(input_data)==0:\n",
    "            input_data = input_subdata\n",
    "        else:\n",
    "            input_data = pd.concat([input_data,input_subdata],axis=1)\n",
    "        if len(compare_data)==0:\n",
    "            compare_data = compare_subdata\n",
    "        else:\n",
    "            compare_data = pd.concat([compare_data,compare_subdata],axis=1)\n",
    "    time.sleep(35)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.dropna(axis=0)\n",
    "compare_data = compare_data[compare_data.index.year>2020]\n",
    "input_data.to_csv('input_data.csv')\n",
    "compare_data.to_csv('compare_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_general_info = pd.read_csv('Du_lieu.csv')\n",
    "col = ticket_general_info.iloc[0].to_list()\n",
    "ticket_general_info.columns = col\n",
    "ticket_general_info = ticket_general_info.drop(index=ticket_general_info.index[0])\n",
    "ticket_general_info.set_index('Công ty',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_of_interest = pd.read_csv('compare_data.csv')\n",
    "ticket_of_interest['time'] = pd.to_datetime(ticket_of_interest['time'])\n",
    "ticket_of_interest.set_index('time',inplace=True)\n",
    "info_of_interest_ticket = ticket_general_info.loc[ticket_of_interest.columns]\n",
    "info_of_interest_ticket.to_csv('info_of_ticket.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67e2a6",
   "metadata": {},
   "source": [
    "<h1>II. Thuat toan phan bo danh muc<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3c11f",
   "metadata": {},
   "source": [
    "<h2>1. Xay dung du lieu dau vao cho mo hinh<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd04711",
   "metadata": {},
   "source": [
    "<h3>1.1. Bo chi tieu dau vao va cac thanh phan phu khac <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefa203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xu ly du lieu dau vao\n",
    "raw_data = pd.read_csv('financial_statements.csv')\n",
    "raw_data['time']= pd.to_datetime(raw_data['time'])\n",
    "raw_data.set_index(['ticket','time'],inplace=True)\n",
    "raw_data = raw_data.sort_index(level='time',ascending=True)\n",
    "raw_data =raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906be3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tinh cac chi tieu trung gian \n",
    "intermediary_data = raw_data['Doanh thu thuần']+raw_data['Thu nhập tài chính']+raw_data['Thu nhập khác']\n",
    "intermediary_data = intermediary_data.to_frame(name='dttn')\n",
    "## chi phí được ghi âm thay vì dương nên cần phải cận thận khi công trừ các chi tiêu này\n",
    "intermediary_data['ebit'] = raw_data['LN trước thuế'] - raw_data['Chi phí tiền lãi vay']\n",
    "intermediary_data['interest'] = - raw_data['Chi phí tiền lãi vay']\n",
    "intermediary_data['dna'] = raw_data['Khấu hao TSCĐ']\n",
    "intermediary_data['capex'] = -raw_data['Mua sắm TSCĐ'] - raw_data['Tiền thu được từ thanh lý tài sản cố định']\n",
    "intermediary_data['wc'] = (raw_data['TÀI SẢN NGẮN HẠN (đồng)']-raw_data['Giá trị thuần đầu tư ngắn hạn (đồng)'] - raw_data[\n",
    "    'Tiền và tương đương tiền (đồng)']) - (raw_data['Nợ ngắn hạn (đồng)']-raw_data['Vay và nợ thuê tài chính ngắn hạn (đồng)'])\n",
    "intermediary_data['debt'] = raw_data['Vay và nợ thuê tài chính ngắn hạn (đồng)']+raw_data['Vay và nợ thuê tài chính dài hạn (đồng)']\n",
    "intermediary_data['equity'] = raw_data['VỐN CHỦ SỞ HỮU (đồng)']\n",
    "intermediary_data['value'] = intermediary_data['debt']+intermediary_data['equity']#day chinh la chi tieu V\n",
    "intermediary_data['TA'] = raw_data['TỔNG CỘNG TÀI SẢN (đồng)']\n",
    "#Tao dung cac mau du lieu dau tien, dữ liệu này là kỳ gần nhất đóng vai trò tính toán ra các dữ liệu trong tương lai ví dụ nhu DTTN\n",
    "latest_time_of_raw_data = raw_data.groupby(level='ticket').last()\n",
    "latest_time_of_intermediary_data =intermediary_data.groupby(level='ticket').last() \n",
    "ind = latest_time_of_raw_data.index\n",
    "col = ['dttn','wc','minor_rate','out_share','cash','debt']\n",
    "initial_data_set = np.full(shape=(len(ind),len(col)),fill_value=0)\n",
    "initial_data_set = pd.DataFrame(initial_data_set,columns=col,index=ind)\n",
    "initial_data_set['dttn'] = latest_time_of_intermediary_data['dttn']\n",
    "initial_data_set['wc'] = latest_time_of_intermediary_data['wc']\n",
    "initial_data_set['minor_rate'] = latest_time_of_raw_data['LỢI ÍCH CỦA CỔ ĐÔNG THIỂU SỐ']/latest_time_of_raw_data['VỐN CHỦ SỞ HỮU (đồng)']\n",
    "initial_data_set['out_share'] = latest_time_of_raw_data['Số CP lưu hành (Triệu CP)']\n",
    "initial_data_set['value'] = latest_time_of_intermediary_data['value']\n",
    "initial_data_set['debt'] = latest_time_of_intermediary_data['debt']\n",
    "initial_data_set['cash'] = latest_time_of_raw_data['Tiền và tương đương tiền (đồng)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('financial_statements.csv')\n",
    "raw_data['time']= pd.to_datetime(raw_data['time'])\n",
    "raw_data.set_index(['ticket','time'],inplace=True)\n",
    "raw_data = raw_data.sort_index(level='time',ascending=True)\n",
    "raw_data =raw_data[raw_data.index.get_level_values(level='time')>=pd.to_datetime('2020-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e282c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Du lieu cho ky so sanh\n",
    "initial_data_set['out_share'] = raw_data['Số CP lưu hành (Triệu CP)'].groupby(level=0).last()\n",
    "deterministic_complementary = pd.DataFrame(raw_data['LỢI ÍCH CỦA CỔ ĐÔNG THIỂU SỐ'\n",
    "                                                    ]/raw_data['VỐN CHỦ SỞ HỮU (đồng)'],columns=['minor_rate'])\n",
    "deterministic_complementary['net_debt'] = raw_data['Vay và nợ thuê tài chính ngắn hạn (đồng)'\n",
    "                                                   ]+raw_data['Vay và nợ thuê tài chính dài hạn (đồng)'\n",
    "                                                              ]- raw_data['Tiền và tương đương tiền (đồng)']\n",
    "deterministic_complementary = deterministic_complementary.join(initial_data_set['out_share'],on='ticket')\n",
    "deterministic_complementary['net_debt_per_share'] = deterministic_complementary['net_debt']/deterministic_complementary['out_share']\n",
    "deterministic_complementary.drop(labels=['out_share','net_debt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67753cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "share = initial_data_set[['out_share']]\n",
    "generated_point = intermediary_data[['dttn','wc','value']]\n",
    "generated_point = generated_point.join(share, on=generated_point.index.names[0])\n",
    "generated_point['dttn']/=generated_point['out_share']\n",
    "generated_point['wc']/=generated_point['out_share']\n",
    "generated_point['value']/=generated_point['out_share']\n",
    "generated_point.drop('out_share',inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bo chi tieu can quan tam\n",
    "input_ratio = np.log(intermediary_data['dttn']/intermediary_data['dttn'].groupby(level='ticket').shift())\n",
    "input_ratio = input_ratio.to_frame(name='g_log')\n",
    "input_ratio['omr'] = intermediary_data['ebit']/intermediary_data['dttn']\n",
    "input_ratio['dpoc'] = intermediary_data['dna']/(intermediary_data['dttn']-intermediary_data['ebit'])\n",
    "input_ratio['lrr'] = intermediary_data['dna']/intermediary_data['capex']\n",
    "input_ratio['wct'] = intermediary_data['dttn']/intermediary_data['wc']\n",
    "input_ratio['hskd'] = intermediary_data['dttn']/intermediary_data['TA']\n",
    "input_ratio['ht'] = intermediary_data['equity']/intermediary_data['TA']\n",
    "input_ratio['wod'] = intermediary_data['debt']/(intermediary_data['TA']-intermediary_data['equity']) \n",
    "input_ratio = input_ratio[input_ratio.index.get_level_values(level=1).year < 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03083d5",
   "metadata": {},
   "source": [
    "<h2>2. Xay dung cau truc phu thuoc giua cac bien<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6283a09",
   "metadata": {},
   "source": [
    "<h3>2.1. Chuan hoa bo chi tieu<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb40a3",
   "metadata": {},
   "source": [
    "<h4>2.1.1. Cac ham lien quan<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xay dung ham phan phoi dua tren gaussian kde\n",
    "data_type = Literal['in_R','minus_infty_to_one','binary','zero_to_infty']\n",
    "infinitesimal = 1e-9\n",
    "quantity_for_intepld = 1000000\n",
    "class kde_distribution:\n",
    "    def __init__(self,data_set,type_of_data:data_type):\n",
    "        self.type = type_of_data\n",
    "        data = data_set.replace([np.inf,-np.inf],np.nan)\n",
    "        data = data_set.dropna()\n",
    "        if self.type == 'in_R':\n",
    "            self.data = data\n",
    "            self.range = np.linspace(-200,200,quantity_for_intepld)\n",
    "        elif self.type == 'minus_infty_to_one':\n",
    "            self.data = -np.log(1-data)\n",
    "            self.range = np.linspace(-200,1-infinitesimal,quantity_for_intepld)\n",
    "        elif self.type == 'binary':\n",
    "            data += infinitesimal\n",
    "            self.data = np.log(data/(1-data))\n",
    "            self.range = np.linspace(0+infinitesimal,1-infinitesimal,quantity_for_intepld)\n",
    "        elif self.type == 'zero_to_infty':\n",
    "            self.data = np.log(data)\n",
    "            self.range = np.linspace(0+infinitesimal,200,quantity_for_intepld)\n",
    "        self.kde = stats.gaussian_kde(self.data)\n",
    "        self._pdf = self.pdf(self.range)\n",
    "        self.cdf_val = np.cumsum(self._pdf)\n",
    "        self.cdf_val/= self.cdf_val[-1]\n",
    "        self._cdf = interp1d(self.range,self.cdf_val,kind='linear',bounds_error=False,fill_value=(0,1))\n",
    "        self._ppf = interp1d(self.cdf_val,self.range,kind='linear',bounds_error=False, fill_value=\"extrapolate\")\n",
    "    def pdf(self, x):\n",
    "        if self.type == 'in_R':\n",
    "           p = self.kde(x)\n",
    "        elif self.type == 'minus_infty_to_one':\n",
    "            p = self.kde(-np.log(1-x))/np.log(1-x) \n",
    "        elif self.type == 'binary':\n",
    "            p = self.kde(np.log(x/(1-x)))/(x-x**2)\n",
    "        elif self.type == 'zero_to_infty':\n",
    "            p = self.kde(np.log(x))/x\n",
    "        return p\n",
    "    def cdf (self,x):\n",
    "        return self._cdf(x)\n",
    "    def ppf (self,u):\n",
    "        return self._ppf(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa3b92",
   "metadata": {},
   "source": [
    "<h4>2.1.2. Thuat toan normalize chi tieu bang CDF<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e06919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phan nhom bo chi tieu\n",
    "in_R = ['g_log','lrr','wct']\n",
    "minus_infty_to_one = ['omr','dpoc']\n",
    "binary = ['ht','wod']\n",
    "zero_to_infty = ['hskd']\n",
    "input_ratio = input_ratio.replace([-np.inf,np.inf],np.nan)\n",
    "ticket = input_ratio.index.get_level_values(level=0).unique()\n",
    "ratio = input_ratio.columns\n",
    "standardised_input_ratio = pd.DataFrame()\n",
    "#Chuan hoa du lieu\n",
    "for i in ticket:\n",
    "    data_set = input_ratio.xs(i,level=0)\n",
    "    single_stock = pd.DataFrame()\n",
    "    for j in ratio:\n",
    "        n = len(data_set[j].dropna())+1\n",
    "        if len(single_stock) == 0:\n",
    "            single_stock = data_set[[j]].rank(method='average')/n\n",
    "        else:\n",
    "            mediate = data_set[[j]].rank(method='average')/n\n",
    "            single_stock = pd.concat([single_stock,mediate],axis=1)\n",
    "    single_stock['ticket'] = i\n",
    "    if len(standardised_input_ratio)==0:\n",
    "        standardised_input_ratio = single_stock\n",
    "    else:\n",
    "        standardised_input_ratio = pd.concat([standardised_input_ratio,single_stock],axis=0)\n",
    "standardised_input_ratio.set_index('ticket',append=True,inplace=True)\n",
    "standardised_input_ratio = standardised_input_ratio.reorder_levels(['ticket','time'],axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c3c28",
   "metadata": {},
   "source": [
    "<h3>2.2. Xay dung thu tu phu thuoc<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad086be",
   "metadata": {},
   "source": [
    "<h4>2.2.1. Su phu thuoc giua cac doanh nghiep voi nhau<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb14e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ma tran MI cua g_log giua cac doanh nghiep voi nhau\n",
    "standardised_g_log = standardised_input_ratio[['g_log']].unstack('ticket').droplevel(level=0,axis=1)\n",
    "outter_correlation_matrix = standardised_g_log.corr(method='kendall')\n",
    "\"\"\" ma trận xếp hạng hệ số tương quan sẽ được xếp giữa trên độ lớn của hệ số tương quan kendall tau(tức là trị tuyết đối)\n",
    "    Xếp hạng được xếp theo dòng và phân theo thứ tự giảm dần tức là hệ số có tương quan cao nhất sẽ được xếp hạng 1\"\"\"\n",
    "outter_rank_matrix = outter_correlation_matrix.abs().rank(axis=1,ascending=False,method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "outter_dependence_tree = []\n",
    "stock = 'AAA'\n",
    "init_stock = [stock]\n",
    "ticket = list(outter_rank_matrix.columns)\n",
    "ticket.remove(stock)\n",
    "while len(ticket) != 0:\n",
    "    mediate_term = []\n",
    "    for i in init_stock:\n",
    "        data = outter_correlation_matrix[i].loc[ticket].sort_values(ascending=True)\n",
    "        most_correlated = data.iloc[0]\n",
    "        if most_correlated==2:\n",
    "            dependence_stock = list(data[data==most_correlated].index)\n",
    "        else:\n",
    "            dependence_stock = [data[data==most_correlated].index[0]]\n",
    "        for j in dependence_stock:\n",
    "            outter_dependence_tree.append(f'{i}-{j}')\n",
    "            ticket.remove(j)\n",
    "            mediate_term.append(j)\n",
    "    init_stock = mediate_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919e6f7",
   "metadata": {},
   "source": [
    "<h4>2.2.2. Su phu thuoc trong doanh nghiep<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket = list(standardised_input_ratio.index.get_level_values(level='ticket').unique())\n",
    "inner_dependence_tree = {}\n",
    "init_ratio = 'g_log'\n",
    "for i in ticket:\n",
    "    sub_independence_tree = []\n",
    "    data = standardised_input_ratio.xs(i, level='ticket')\n",
    "    ratio = list(data.columns)\n",
    "    init_set = [init_ratio]\n",
    "    ratio.remove(init_ratio)\n",
    "    corr_matrix = data.corr(method='kendall')\n",
    "    rank_matrix = corr_matrix.abs().rank(axis=1,ascending=False,method='min')\n",
    "    while len(ratio) != 0 :\n",
    "        mediate_term = []\n",
    "        for j in init_set:\n",
    "            if len(ratio)==0:\n",
    "                break\n",
    "            rank_of_interest = rank_matrix[j].loc[ratio].sort_values(ascending=True)\n",
    "            most_correlated = rank_of_interest.iloc[0]\n",
    "            if most_correlated == 2:\n",
    "                dependence_set = list(rank_of_interest[rank_of_interest==2].index)\n",
    "            else:\n",
    "                dependence_set = [rank_of_interest.index[0]]\n",
    "            for t in dependence_set:\n",
    "                sub_independence_tree.append(f'{j}-{t}')\n",
    "                ratio.remove(t)\n",
    "                mediate_term.append(t)\n",
    "        init_set = mediate_term\n",
    "    inner_dependence_tree[i] = sub_independence_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a68b7",
   "metadata": {},
   "source": [
    "<h3>2.3. Xay dung cau truc phu thuoc<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = FitControlsBicop(selection_criterion='aic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data:np.ndarray, sample_size:int, simulation_size:int):\n",
    "    \"\"\"Bootstrapping function\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray) shape=(n,d)\n",
    "        sample_size (int)\n",
    "        simulation_size (int): how many times bootstrapping\n",
    "    \n",
    "    Return:\n",
    "    ------------\n",
    "        data (np.ndarray) shape(simulation_size, sample_size, d)\n",
    "    \"\"\"\n",
    "    n = len(data)-1 #vi tri diem cuoi cua data\n",
    "    position = np.random.randint(0,n,size=(simulation_size,sample_size))\n",
    "    return data[position]\n",
    "def empirical_cdf (data:np.ndarray):\n",
    "    \"\"\"Empirical cdf used empirical data as the proxy for true cdf which is P(X <= x)\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): shape = (n,d)\n",
    "        x (np.ndarray): shape = (n,1,d)\n",
    "        X (np.ndarray): shape = (1,n,d)\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "        A float number lies in range (0,1)^n \\in R^n\n",
    "        \n",
    "    \"\"\"\n",
    "    x = data[:,None,:]\n",
    "    X = data[None,:,:]\n",
    "    return np.mean(np.all(X<=x,axis=2),axis=0)\n",
    "class Cvm_test:\n",
    "    def __init__(self,cop_func):\n",
    "        self.copula = cop_func\n",
    "    def CvM_statistic(self,data:np.ndarray):\n",
    "        \"\"\"Cramer - Von Mises statistic\n",
    "            Formula:\n",
    "            \\sum_{i=1}^n{(C_n(u_i)-C_{\\theta}(u_i))^2}\n",
    "        Args:\n",
    "            data (np.ndarray): \n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        C_n = empirical_cdf(data)\n",
    "        C_theta = self.copula.cdf(data)\n",
    "        return np.sum((C_n-C_theta)**2)\n",
    "    def pvalue(self,data:np.ndarray,number_of_simulation:int,sample_size:int):\n",
    "        \"\"\"Pvalue of Cramer - Von Mises statistic\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): shape = (n,d)\n",
    "            number_of_simulation (int): \n",
    "            sample_size (int): \n",
    "\n",
    "        Returns:\n",
    "            a number lies in (0,1)\n",
    "        \"\"\"\n",
    "        bootstrap_data = bootstrap(data,simulation_size=number_of_simulation,sample_size=sample_size)\n",
    "        statistic = self.CvM_statistic(data)\n",
    "        CvM_stats_vector = []\n",
    "        CvM_stats_vector = np.array([self.CvM_statistic(i) for i in bootstrap_data])\n",
    "        return np.mean(CvM_stats_vector>=statistic)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb30087",
   "metadata": {},
   "source": [
    "<h4>2.3.1. Su phu thuoc giua cac doanh nghiep voi nhau<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "outter_dependence_structure = {}\n",
    "number_of_bootsrapping = 10000\n",
    "ticker = list(standardised_input_ratio.index.get_level_values(level='ticket').unique())\n",
    "CvM_pvalue_matrix = np.full(shape=(len(ticker),len(ticker)),fill_value=np.nan)\n",
    "CvM_pvalue_matrix = pd.DataFrame(CvM_pvalue_matrix,index=ticker,columns=ticker)\n",
    "for pair in outter_dependence_tree:\n",
    "    pair_name = pair.split('-')\n",
    "    data = standardised_g_log[pair_name].dropna()\n",
    "    uv = data.to_numpy()\n",
    "    cop_func = Bicop()\n",
    "    cop_func.select(uv,controls=controls)\n",
    "    # test = Cvm_test(cop_func)\n",
    "    # pvalue = test.pvalue(uv, number_of_simulation=number_of_bootsrapping,sample_size=uv.shape[0])\n",
    "    # CvM_pvalue_matrix.loc[pair_name[0],pair_name[1]] = pvalue\n",
    "    outter_dependence_structure[pair] = cop_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52c39",
   "metadata": {},
   "source": [
    "<h4>2.3.2. Su phu thuoc ben trong doanh nghiep(giua cac chi tieu voi nhau)<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ba137",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = list(standardised_input_ratio.index.get_level_values(level='ticket').unique())\n",
    "list_of_ratio = standardised_input_ratio.columns.to_list()\n",
    "inner_cvm_pvalue = pd.DataFrame()\n",
    "number_of_bootsrapping = 10000\n",
    "inner_dependence_structure = {}\n",
    "n = len(list_of_ratio)\n",
    "for i in ticker:\n",
    "    sub_pvalue_matrix = np.full(shape=(n,n),fill_value=np.nan)\n",
    "    sub_pvalue_matrix = pd.DataFrame(sub_pvalue_matrix,index=list_of_ratio,columns=list_of_ratio)\n",
    "    sub_inner_dependence_tree = inner_dependence_tree[i]\n",
    "    data = standardised_input_ratio.xs(i,level='ticket')\n",
    "    single_stock = {}\n",
    "    for pair in sub_independence_tree:\n",
    "        ratio_pair = pair.split('-')\n",
    "        uv = data[ratio_pair].dropna().to_numpy()\n",
    "        cop_func = Bicop()\n",
    "        cop_func.select(uv,controls=controls)\n",
    "        single_stock[pair] = cop_func\n",
    "        # test = Cvm_test(cop_func)\n",
    "        # pvalue = test.pvalue(uv,number_of_simulation=number_of_bootsrapping,sample_size=uv.shape[0])\n",
    "        # sub_pvalue_matrix.loc[ratio_pair[0],ratio_pair[1]] = pvalue\n",
    "    # sub_pvalue_matrix['ticket'] = i\n",
    "    inner_dependence_structure[i] = single_stock\n",
    "#     if len(inner_cvm_pvalue)==0:\n",
    "#         inner_cvm_pvalue = sub_pvalue_matrix\n",
    "#     else:\n",
    "#         inner_cvm_pvalue = pd.concat([inner_cvm_pvalue,sub_pvalue_matrix],axis=0)\n",
    "# inner_cvm_pvalue.index.names = ['ratio']\n",
    "# inner_cvm_pvalue.set_index('ticket',append=True,inplace=True)\n",
    "# inner_cvm_pvalue = inner_cvm_pvalue.reorder_levels(['ticket','ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a21a514",
   "metadata": {},
   "source": [
    "<h2>3. Xay dung phan phoi xac suat cho ky so sanh<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1edb84",
   "metadata": {},
   "source": [
    "<h3>3.1. Xay dung cac ham can su dung<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_R = ['g_log','lrr','wct']\n",
    "minus_infty_to_one = ['omr']\n",
    "binary = ['ht','wod','dpoc']\n",
    "zero_to_infty = ['hskd']\n",
    "data_type = Literal['in_R','minus_infty_to_one','binary','zero_to_infty']\n",
    "def objective_function_theta(parameter_vector:np.ndarray, q_vector:np.ndarray, projection_vector:np.ndarray, type: data_type,infinitesimal:float  ):\n",
    "    \"\"\"Objective function is the function that have to be optimized to estimate parameter for projected distribution\n",
    "\n",
    "    Args:\n",
    "        parameter_vector (np.ndarray): [alpha, beta]\n",
    "        q_vector (np.ndarray): shape = (n,) represent quantile position of projected value\n",
    "        projection_vector (np.ndarray): shape = (n,) the vector of projected value\n",
    "        infinitestimal (float): use when there is overlap in projection vector \n",
    "    Return\n",
    "    -------\n",
    "        Output is a real number\n",
    "    \"\"\"\n",
    "    if type == 'binary':\n",
    "        data_vector = projection_vector\n",
    "    elif type == 'in_R':\n",
    "        data_vector = 1/(1+np.exp(-projection_vector))\n",
    "    elif type == 'minus_infty_to_one':\n",
    "        data_vector = 2/(1+np.exp(1-projection_vector))\n",
    "    elif type == 'zero_to_infty':\n",
    "        data_vector = projection_vector/(1+projection_vector)\n",
    "    if len(np.unique(data_vector)) == 1:\n",
    "        adjust_lower = np.array([i*infinitesimal for i in range(0,len(data_vector))])\n",
    "        adjust_upper = adjust_lower[::-1]\n",
    "        boon_type = abs(0-data_vector[0]) <= abs(1-data_vector[-1])\n",
    "        data_vector = data_vector + boon_type*adjust_lower - (1-boon_type)*adjust_upper\n",
    "    alpha, beta = parameter_vector\n",
    "    quantile_vector = stats.beta.cdf(data_vector,a = alpha, b = beta)\n",
    "    deviation_vector = q_vector - quantile_vector\n",
    "    return deviation_vector.T@deviation_vector\n",
    "def optimize_function (q_vector:np.ndarray, projection_vector:np.ndarray, type: data_type,infinitesimal:float):\n",
    "    \"\"\"Objective function is the function that have to be optimized to estimate parameter for projected distribution\n",
    "\n",
    "    Args:\n",
    "        q_vector (np.ndarray): shape = (n,) represent quantile position of projected value\n",
    "        projection_vector (np.ndarray): shape = (n,) the vector of projected value\n",
    "        infinitestimal (float): use when there is overlap in projection vector \n",
    "        \n",
    "    Return\n",
    "    -------\n",
    "        A np.ndarray of alpha and beta\n",
    "    \"\"\"\n",
    "    bounds = [(1e-9,1e9),(1e-9,1e9)]\n",
    "    init = [0.1,0.1]\n",
    "    res = minimize(objective_function_theta,init,args=(q_vector,projection_vector,type,infinitesimal),bounds=bounds)\n",
    "    return res.x\n",
    "class projected_distribution:\n",
    "    def __init__(self,q_vector:np.ndarray,projected_vector:np.ndarray, data_type:data_type,infinitesimal:float):\n",
    "        self.type = data_type\n",
    "        self.alpha, self.beta = optimize_function(q_vector,projected_vector,self.type,infinitesimal)\n",
    "        self.loss = objective_function_theta(np.array([self.alpha,self.beta]),q_vector,projected_vector,self.type,infinitesimal)\n",
    "    def pdf (self, x):\n",
    "        if self.type == 'binary':\n",
    "            x_trans = x\n",
    "            pdf_val = stats.beta.pdf(x_trans,a=self.alpha,b=self.beta)\n",
    "        elif self.type == 'in_R':\n",
    "            x_trans = 1/(1+np.exp(-x))\n",
    "            pdf_val = stats.beta.pdf(x_trans,a=self.alpha,b=self.beta)*np.exp(-x)/(1+np.exp(-x))**2\n",
    "        elif self.type == 'minus_infty_to_one':\n",
    "            x_trans = 2/(1+np.exp(1-x))\n",
    "            pdf_val = stats.beta.pdf(x_trans,a=self.alpha,b=self.beta)*2*np.exp(1-x)/(1+np.exp(1-x))**2\n",
    "        elif self.type == 'zero_to_infty':\n",
    "            x_trans = x/(1+x)\n",
    "            pdf_val = stats.beta.pdf(x_trans,a=self.alpha,b=self.beta)/(1+x)**2\n",
    "        return pdf_val\n",
    "    def cdf (self, x):\n",
    "        if self.type == 'binary':\n",
    "            x_trans = x \n",
    "        elif self.type == 'in_R':\n",
    "            x_trans = 1/(1+np.exp(-x))\n",
    "        elif self.type == 'minus_infty_to_one':\n",
    "            x_trans = 2/(1+np.exp(1-x))\n",
    "        elif self.type == 'zero_to_infty':\n",
    "            x_trans = x/(1+x)\n",
    "        cdf_val = stats.beta.cdf(x_trans,a=self.alpha,b=self.beta)  \n",
    "        return cdf_val\n",
    "    def ppf (self, u,lower_bounds,upper_bounds):\n",
    "        x_trans = stats.beta.ppf(u,a=self.alpha,b=self.beta)\n",
    "        if self.type == 'binary':\n",
    "            ppf_val = x_trans\n",
    "        elif self.type == 'in_R':\n",
    "            ppf_val = np.log(x_trans/(1-x_trans))\n",
    "            ppf_val = np.clip(ppf_val,lower_bounds,upper_bounds)\n",
    "        elif self.type == 'minus_infty_to_one':\n",
    "            ppf_val = np.log(x_trans/(2-x_trans))+1\n",
    "            ppf_val = np.clip(ppf_val,-lower_bounds,1)\n",
    "        elif self.type == 'zero_to_infty':\n",
    "           ppf_val = x_trans/(1-x_trans)\n",
    "           ppf_val = np.clip(ppf_val,1e-6,upper_bounds)\n",
    "        return ppf_val\n",
    "    def loss (self):\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517b684",
   "metadata": {},
   "source": [
    "<h3>3.2. Thuat toan<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lay du lieu\n",
    "input_data = pd.read_csv('ratio_data.csv')\n",
    "input_data['time'] = pd.to_datetime(input_data['time'])\n",
    "input_data = input_data.sort_values('time',ascending=True)\n",
    "input_data.set_index(['ticket','time'],inplace=True)\n",
    "input_data = input_data[input_data.index.get_level_values(level='time').year>2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964953fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dau vao de xac dinh phan phoi xac suat\n",
    "adjusted_range = 1\n",
    "ticker = list(standardised_input_ratio.index.get_level_values(level='ticket').unique())\n",
    "q_vector = np.array([0.05,0.25,0.5,0.75,0.95])\n",
    "data_for_distribution = pd.DataFrame()\n",
    "for i in q_vector:\n",
    "    name = f'Q{i}'\n",
    "    q = input_data.groupby(level='ticket').quantile(i)\n",
    "    q['Q'] = name\n",
    "    q.set_index('Q',inplace=True, append=True)\n",
    "    q = q.unstack(level=1).stack(level=0)\n",
    "    if len(data_for_distribution) == 0:\n",
    "        data_for_distribution = q\n",
    "    else:\n",
    "        data_for_distribution = pd.concat([data_for_distribution,q],axis=1)\n",
    "\n",
    "lower = input_data.groupby(level=\"ticket\").min()\n",
    "lower['range'] ='L'\n",
    "lower.set_index('range',inplace=True,append=True)\n",
    "lower = lower.unstack(level=1).stack(level=0)\n",
    "lower[lower>0]/=adjusted_range\n",
    "lower[lower<=0]*=adjusted_range\n",
    "\n",
    "upper = input_data.groupby(level=\"ticket\").max()\n",
    "upper['range'] ='U'\n",
    "upper.set_index('range',inplace=True,append=True)\n",
    "upper = upper.unstack(level=1).stack(level=0)\n",
    "upper[upper>0]*adjusted_range\n",
    "upper[upper<=0]/=adjusted_range\n",
    "range_input = pd.concat([lower,upper],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luu tru phan phoi xac xuat\n",
    "in_R = ['g_log','lrr','wct']\n",
    "minus_infty_to_one = ['omr']\n",
    "binary = ['ht','wod','dpoc']\n",
    "zero_to_infty = ['hskd']\n",
    "infinitesimal = 1e-9\n",
    "ticker = list(standardised_input_ratio.index.get_level_values(level='ticket').unique())\n",
    "projected_distribution_dict = {}\n",
    "for i in ticker:\n",
    "    data = data_for_distribution.xs(i,level='ticket')\n",
    "    store_dict = {}\n",
    "    ind = data.index.to_list()\n",
    "    for j in ind:\n",
    "        projected_vector = data.loc[j].to_numpy()\n",
    "        if j in in_R:\n",
    "            func = projected_distribution(q_vector=q_vector,\n",
    "                                          projected_vector=projected_vector,\n",
    "                                          data_type='in_R',infinitesimal=infinitesimal)\n",
    "        elif j in minus_infty_to_one:\n",
    "            func = projected_distribution(q_vector=q_vector,\n",
    "                                          projected_vector=projected_vector,\n",
    "                                          data_type='minus_infty_to_one',infinitesimal=infinitesimal)\n",
    "        elif j in binary:\n",
    "            func = projected_distribution(q_vector=q_vector,\n",
    "                                          projected_vector=projected_vector,\n",
    "                                          data_type='binary',infinitesimal=infinitesimal)\n",
    "        elif j in zero_to_infty:\n",
    "            func = projected_distribution(q_vector=q_vector,\n",
    "                                          projected_vector=projected_vector,\n",
    "                                          data_type='zero_to_infty',infinitesimal=infinitesimal)\n",
    "        \n",
    "        store_dict[j] = func\n",
    "    projected_distribution_dict[i] = store_dict                     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1913e",
   "metadata": {},
   "source": [
    "<h2>4. Cac tham so cho Wacc(chi phi su dung von binh quan)<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28abeee",
   "metadata": {},
   "source": [
    "<h3>4.1. Chi phi su dung von chu <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Du lieu ve market_portfolio\n",
    "rm_data = pd.read_csv('VNI_price.csv')\n",
    "rm_data['time'] = pd.to_datetime(rm_data['time'])\n",
    "rm_data.set_index('time',inplace=True)\n",
    "rm_data = rm_data[(rm_data.index.year<2021)&(rm_data.index.year > 2015)]\n",
    "rm_data = rm_data.pct_change()\n",
    "#du lieu ve cac co phieu\n",
    "stock_return = pd.read_csv('input_data.csv')\n",
    "stock_return['time'] = pd.to_datetime(stock_return['time'])\n",
    "stock_return.set_index('time',inplace=True)\n",
    "stock_return = stock_return[(stock_return.index.year < 2021) & (stock_return.index.year > 2015)]\n",
    "stock_return = stock_return.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tinh beta\n",
    "beta_vector = []\n",
    "beta_dict = {}\n",
    "ticker = list(standardised_input_ratio.index.get_level_values(level='ticket').unique())\n",
    "for i in ticker:\n",
    "    y = stock_return[i]\n",
    "    uv = pd.concat([rm_data,y],axis=1)\n",
    "    uv.dropna(inplace=True)\n",
    "    covariance_matrix = uv.cov()\n",
    "    beta = covariance_matrix.iloc[0,1]/covariance_matrix.iloc[0,0]\n",
    "    beta_vector.append(beta)\n",
    "    beta_dict[i] = beta\n",
    "beta_vector = np.array(beta_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc09e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cac tham so khac\n",
    "rf = pd.read_csv('interest_rate_10_year_goverment_bond.csv')\n",
    "rf['time'] = pd.to_datetime(rf['time'])\n",
    "rf.set_index('time', inplace=True)\n",
    "annual_estimated_rf = rf[rf.index.year > 2020].mean().values/100\n",
    "\n",
    "rm = pd.read_csv('VNI_price.csv')\n",
    "rm['time'] = pd.to_datetime(rm['time'])\n",
    "rm.set_index('time', inplace=True)\n",
    "rm = rm.pct_change()\n",
    "annual_estimated_rm = rm[rm.index.year > 2020].mean().values*12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_re_data = annual_estimated_rf + beta_vector*(annual_estimated_rm-annual_estimated_rf)\n",
    "annual_re_data = pd.DataFrame(annual_re_data,index=ticker,columns=['re'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5946d92",
   "metadata": {},
   "source": [
    "<h4>4.2. Chi phi su dung no binh quan<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fac03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_related_data = pd.read_csv('intermediary_data.csv')\n",
    "debt_related_data['time'] = pd.to_datetime(debt_related_data['time'])\n",
    "debt_related_data.set_index(['ticket','time'],inplace=True)\n",
    "debt_related_data = debt_related_data.sort_index(level=0,ascending=True)\n",
    "debt_related_data = debt_related_data[['interest','debt']]\n",
    "debt_related_data['average_debt'] = debt_related_data['debt'].groupby(level=0).rolling(window=2).mean().droplevel(level=0)\n",
    "debt_related_data['cod'] = debt_related_data['interest']/debt_related_data['average_debt']\n",
    "annual_estimated_cod = debt_related_data['cod'].groupby(level=0).mean().replace(np.inf,np.nan)*4\n",
    "annual_estimated_cod = annual_estimated_cod.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69981d0",
   "metadata": {},
   "source": [
    "<h2>5. Mo phong Monte Carlo<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_size = 10000\n",
    "simulated_col = np.arange(1,simulated_size+1)\n",
    "lower_bounds = 0.05\n",
    "upper_bounds = 0.95\n",
    "simulated_ind = pd.date_range(start='2021-01-01',end='2026-01-01',freq='1Q')\n",
    "origin = np.random.uniform(lower_bounds,upper_bounds, size=(len(simulated_ind),simulated_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d142477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditioned_simulation (u1:np.ndarray, copula_func):\n",
    "    \"\"\" We have the following conditional distribution p(u2|u1) and we want to simulate u2 by\n",
    "    this conditional distribution\n",
    "\n",
    "    Args:\n",
    "        u1 (np.ndarray): observed data\n",
    "        copula_func (_type_): act as the activation conditional distribution\n",
    "        \n",
    "    Return:\n",
    "    An np.ndarray have the same shape as u1\n",
    "    \"\"\"\n",
    "    shape = u1.shape\n",
    "    processed_u1 = u1.reshape(-1,1)\n",
    "    prob = np.random.uniform(lower_bounds,upper_bounds,size=processed_u1.shape)\n",
    "    u = np.column_stack([prob,processed_u1])\n",
    "    u2 = cop_func.hinv2(u)\n",
    "    return u2.reshape(shape[0],shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715103f7",
   "metadata": {},
   "source": [
    "<h3>5.1. chi tieu g_log cua cac doanh nghiep trong khung chuan hoa<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884fed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_simulated_glog_dict = {}\n",
    "for i in outter_dependence_structure.keys():\n",
    "    pair_of_share = i.split('-')\n",
    "    s1, s2 = pair_of_share\n",
    "    if len(uni_simulated_glog_dict) == 0:\n",
    "        uni_simulated_glog_dict[s1] = origin\n",
    "    \n",
    "    function = outter_dependence_structure[i]\n",
    "    u1 = uni_simulated_glog_dict[s1]\n",
    "    u2 = conditioned_simulation(u1,function)\n",
    "    uni_simulated_glog_dict[s2] = u2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dac13f",
   "metadata": {},
   "source": [
    "<h3>5.2. Bo chi tieu trong khung chuan hoa<h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_of_interest = pd.read_csv('ratio_data.csv').columns[2::].to_list()\n",
    "ticker = pd.read_csv('ratio_data.csv')['ticket'].unique().tolist()\n",
    "uni_simulation_dict = {}\n",
    "for i in inner_dependence_structure.keys():\n",
    "    single_stock_dict = {}\n",
    "    sub_structure = inner_dependence_structure[i]\n",
    "    for j in sub_structure.keys():\n",
    "        function = sub_structure[j]\n",
    "        ratio_1, ratio_2 = j.split('-')\n",
    "        if len(single_stock_dict)==0:\n",
    "            single_stock_dict[ratio_1] = uni_simulated_glog_dict[i]\n",
    "        u1 = single_stock_dict[ratio_1]\n",
    "        u2 = conditioned_simulation(u1,function)\n",
    "        single_stock_dict[ratio_2] = u2\n",
    "    uni_simulation_dict[i] = single_stock_dict\n",
    "del uni_simulated_glog_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfff3c8",
   "metadata": {},
   "source": [
    "<h3>5.3. Gia tri du bao cua bo chi tieu<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_dict = {}\n",
    "for i in uni_simulation_dict.keys():\n",
    "    sub_data = uni_simulation_dict[i]\n",
    "    function_set = projected_distribution_dict[i]\n",
    "    bound = range_input.xs(i,level=0)\n",
    "    sub_simulation = {}\n",
    "    for j in sub_data.keys():\n",
    "        function = function_set[j]\n",
    "        u = sub_data[j]\n",
    "        low = bound.loc[j,'L']\n",
    "        up = bound.loc[j,'U']\n",
    "        projected = function.ppf(u,low,up)\n",
    "        sub_simulation[j] = projected\n",
    "    simulation_dict[i] = sub_simulation\n",
    "del uni_simulation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af6817d",
   "metadata": {},
   "source": [
    "<h2>6. Phan phoi loi suat sinh loi<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a383ba1",
   "metadata": {},
   "source": [
    "<h3>6.1. Cac ham can su dung<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_value_function (cf: np.ndarray, wacc: np.ndarray, v_0: np.ndarray, v_1: np.ndarray):\n",
    "    \"\"\"Calculating the continuous cashflow\n",
    "\n",
    "    Args:\n",
    "        cf (np.ndarray): matrix represent the simulation of FCFF over time, shape = (t,n)\n",
    "        wacc (np.ndarray): matrix represent the simulation of wacc overtime, shape = (t,n)\n",
    "        v_0 (np.ndarray): matrix represent the simulation of firm value at the start of a period, shape = (t,n)\n",
    "        v_1 (np.ndarray): matrix represent the simulation of firm value at the end of a period, shape = (t,n)\n",
    "    \n",
    "    Returns:\n",
    "        A matrix represent of present value of cashflow at each period, shape = (t,n)\n",
    "    \"\"\"\n",
    "    one_matrix = np.full(shape=wacc.shape,fill_value=1)\n",
    "    cum_wacc = np.cumsum(wacc,axis=0)\n",
    "    delta_v = v_1 - v_0\n",
    "    average_v = (v_0+v_1)/2\n",
    "    first_term = 1/(wacc * np.exp(cum_wacc))\n",
    "    second_term = v_0*(np.exp(wacc) - one_matrix) + delta_v*(np.exp(wacc) -wacc - 1)/wacc\n",
    "    third_term = cf/average_v\n",
    "    return first_term*second_term*third_term\n",
    "def future_value_function (cf: np.ndarray, wacc: np.ndarray, v_0: np.ndarray, v_1: np.ndarray):\n",
    "    \"\"\"Calculating the continuous cashflow\n",
    "\n",
    "    Args:\n",
    "        cf (np.ndarray): matrix represent the simulation of FCFF over time, shape = (t,n)\n",
    "        wacc (np.ndarray): matrix represent the simulation of wacc overtime, shape = (t,n)\n",
    "        v_0 (np.ndarray): matrix represent the simulation of firm value at the start of a period, shape = (t,n)\n",
    "        v_1 (np.ndarray): matrix represent the simulation of firm value at the end of a period, shape = (t,n)\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "        A matrix represent of future value of cashflow at each period, shape = (t,n)\n",
    "    \"\"\"\n",
    "    time_length = wacc.shape[0]\n",
    "    present_value = present_value_function(cf,wacc,v_0,v_1)\n",
    "    cum_wacc = np.sum(wacc,axis=0)\n",
    "    adjust_term = np.tile(cum_wacc,(time_length,1))\n",
    "    return present_value*np.exp(adjust_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b07f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_condition (data:np.ndarray):\n",
    "    \"\"\"working like if else function\n",
    "\n",
    "    Returns:\n",
    "    An array has the same shape as data in which:\n",
    "    If x > 0: return 1\n",
    "    If x < 0: return 0\n",
    "    \"\"\"\n",
    "    sign_matrix = np.sign(data)\n",
    "    return abs((sign_matrix+1)/2)\n",
    "def negative_condition (data:np.ndarray):\n",
    "    \"\"\"working like if else function\n",
    "\n",
    "    Returns:\n",
    "    An array has the same shape as data in which\n",
    "    If x < 0: return 1\n",
    "    If x > 0: return 0\n",
    "    \"\"\"   \n",
    "    one_matrix = np.full(shape=data.shape, fill_value=1)\n",
    "    sign_matrix = np.sign(data)\n",
    "    return -(sign_matrix-one_matrix)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf843564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EV_calculation (cf: np.ndarray, wacc: np.ndarray, v_0: np.ndarray, v_1: np.ndarray, r_inf: float):\n",
    "    \"\"\"Calculating enterprise value\n",
    "\n",
    "    Args:\n",
    "        cf (np.ndarray): matrix represent the simulation of FCFF over time, shape = (t,n)\n",
    "        wacc (np.ndarray): matrix represent the simulation of wacc overtime, shape = (t,n)\n",
    "        v_0 (np.ndarray): matrix represent the simulation of firm value at the start of a period, shape = (t,n)\n",
    "        v_1 (np.ndarray): matrix represent the simulation of firm value at the end of a period, shape = (t,n)\n",
    "        r_inf (float): inflation rate\n",
    "    \n",
    "    Returns:\n",
    "        A vector of EV\n",
    "    \"\"\"\n",
    "    present_value = present_value_function(cf,wacc,v_0,v_1)\n",
    "    postive_present_value = present_value_function(cf,wacc,v_0,v_1)*positive_condition(present_value)\n",
    "    tpv = np.sum(postive_present_value,axis=0)\n",
    "    cum_wacc_vector = np.sum(wacc,axis=0)\n",
    "    r_inf_matrix = r_inf*np.full(shape=cf.shape,fill_value=1)\n",
    "    total_rinf = np.sum(r_inf_matrix,axis=0)\n",
    "    first_term = tpv*np.exp(cum_wacc_vector)\n",
    "    second_term = np.exp(cum_wacc_vector)-np.exp(total_rinf*positive_condition(np.exp(cum_wacc_vector)-np.exp(total_rinf)))\n",
    "    return first_term/second_term\n",
    "def hidden_cost_function (cf: np.ndarray, wacc: np.ndarray, v_0:np.ndarray, v_1: np.ndarray):\n",
    "    \"\"\"Calculating hidden cost\n",
    "\n",
    "    Args:\n",
    "        cf (np.ndarray): matrix represent the simulation of FCFF over time, shape = (t,n)\n",
    "        wacc (np.ndarray): matrix represent the simulation of wacc overtime, shape = (t,n)\n",
    "        v_0 (np.ndarray): matrix represent the simulation of firm value at the start of a period, shape = (t,n)\n",
    "        v_1 (np.ndarray): matrix represent the simulation of firm value at the end of a period, shape = (t,n)\n",
    "    \n",
    "    Returns:\n",
    "        A vector of hidden cost\n",
    "    \"\"\" \n",
    "    present_value = present_value_function(cf,wacc,v_0,v_1)\n",
    "    negative_present_value = present_value*negative_condition(present_value)\n",
    "    return -np.sum(negative_present_value,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benefit_function (cf: np.ndarray, wacc: np.ndarray, v_0: np.ndarray, v_1: np.ndarray, r_inf: float):\n",
    "    \"\"\"Calculating the numerator in return formula\n",
    "\n",
    "    Args:\n",
    "        cf (np.ndarray): matrix represent the simulation of FCFF over time, shape = (t,n)\n",
    "        wacc (np.ndarray): matrix represent the simulation of wacc overtime, shape = (t,n)\n",
    "        v_0 (np.ndarray): The latest reported v matrix\n",
    "        v_1 (np.ndarray): projected v matrix\n",
    "        r_inf (float): inflation rate\n",
    "    \n",
    "    Returns:\n",
    "        A matrix of benefit\n",
    "    \"\"\"\n",
    "    EV_0 = EV_calculation(cf,wacc,v_0,v_1,r_inf)\n",
    "    future_value = future_value_function(cf,wacc,v_0,v_1)\n",
    "    positive_future_value = future_value*positive_condition(future_value)\n",
    "    tfv = np.sum(positive_future_value,axis=0)\n",
    "    return tfv + EV_0 * np.exp(r_inf*cf.shape[0])\n",
    "def projected_return (cf: np.ndarray, wacc: np.ndarray, v_0: np.ndarray, v_1: np.ndarray, r_inf: float,current_market_price:float,net_debt:np.ndarray,minority:float,period_per_year:float):\n",
    "    \"\"\"Estimating the distribution of stock return\n",
    "\n",
    "    Args:\n",
    "        cf (np.ndarray): matrix represent the simulation of FCFF over time, shape = (t,n)\n",
    "        wacc (np.ndarray): matrix represent the simulation of wacc overtime, shape = (t,n)\n",
    "        v_0 (np.ndarray): matrix represent the simulation of firm value at the start of a period, shape = (t,n)\n",
    "        v_1 (np.ndarray): matrix represent the simulation of firm value at the end of a period, shape = (t,n)\n",
    "        r_inf (float): annual inflation rate\n",
    "        current_market_price (float): market price\n",
    "        net_debt (np.ndarray): debt - cash\n",
    "        minority (float): ratio of minority shareholders and total shareholders\n",
    "        period_per_year (float): number of period per year\n",
    "    \"\"\"\n",
    "    benefit = benefit_function(cf,wacc,v_0,v_1,r_inf)*(1-minority)\n",
    "    cost = current_market_price + (hidden_cost_function(cf,wacc,v_0,v_1) + net_debt)*(1-minority)\n",
    "    hpr = benefit/cost\n",
    "    number_of_period = cf.shape[0]\n",
    "    number_of_year = number_of_period/period_per_year\n",
    "    return hpr**(1/number_of_year)-1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cdea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_set_generate (ticker: list, generator: pd.DataFrame, simulation_ratio: dict, \n",
    "                        current_date, tax_rate: float,annual_re:pd.DataFrame, annual_cod:pd.DataFrame):\n",
    "    \"\"\"Generating dictionary of FCFF and dictionary of wacc and value\n",
    "\n",
    "    Args:\n",
    "        ticker (list): the list of stock\n",
    "        generator (pd.DataFrame): the latest reported dttn, working capital and value\n",
    "        simulation_ratio (dict): dictionary of simulation ratio\n",
    "        current_date (_type_): \n",
    "        tax_rate (float): corporate level of tax\n",
    "        annual_re (pd.DataFrame): contains ownerships required rate of return of each stock in ticker list\n",
    "        annual_cod (pd.DataFrame): contains cost of using debt of each stock in ticker list\n",
    "\n",
    "    Returns:\n",
    "        (list): contain FCFF dictionary and dictionary of wacc and value\n",
    "    \"\"\"\n",
    "    latest_reported_date = current_date - pd.offsets.QuarterEnd()\n",
    "    gen_data = generator.xs(latest_reported_date,level='time')\n",
    "    output = []\n",
    "    FCFF = {}\n",
    "    complementary_dict = {}\n",
    "    for i in ticker:\n",
    "        complementary = {}\n",
    "        simulation_set = simulation_ratio[i]\n",
    "        dttn_0, wc_0,v_0 = gen_data.loc[i].tolist()\n",
    "        cummulative_glog = np.cumsum(simulation_set['g_log'],axis=0)\n",
    "        dttn = dttn_0*np.exp(cummulative_glog)\n",
    "        ebit = dttn*simulation_set['omr']\n",
    "        dna = (dttn - ebit)*simulation_set['dpoc']\n",
    "        capex = dna*simulation_set['lrr']\n",
    "    \n",
    "        wct = np.maximum(np.abs(simulation_set['wct']),0.1)*np.sign(simulation_set['wct'])\n",
    "        wc = dttn/wct\n",
    "        wc_0 = np.full(shape=(1,dttn.shape[1]),fill_value=wc_0)\n",
    "        full_wc = np.vstack([wc_0,wc])\n",
    "        delta_wc = np.diff(full_wc,axis=0)\n",
    "    \n",
    "        cf = ebit*(1-tax_rate) + dna  - capex - delta_wc\n",
    "        FCFF[i] = cf\n",
    "    \n",
    "        equity = dttn*simulation_set['ht']/simulation_set['hskd']\n",
    "        debt = (1-simulation_set['ht'])/simulation_set['ht']*equity*simulation_set['wod']\n",
    "        value = equity + debt\n",
    "        epv = equity/value\n",
    "        initial_value = np.full(shape=(1,value.shape[1]),fill_value=v_0)\n",
    "        value = np.vstack([initial_value,value])\n",
    "    \n",
    "        re = annual_re['re'].loc[i]\n",
    "        cod = annual_cod.loc[i]\n",
    "        wacc = epv*re + (1-epv)*cod*(1-tax_rate)\n",
    "    \n",
    "        complementary['value'] = value\n",
    "        complementary['wacc'] = wacc\n",
    "\n",
    "        complementary_dict[i] = complementary\n",
    "    [FCFF, complementary_dict]  \n",
    "    return [FCFF, complementary_dict] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a59a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_selection = Literal['annual','quarter']\n",
    "def return_matrix_construction (ticker: list, cf_dict:dict,complementary: dict, \n",
    "                                deterministic_complementary:pd.DataFrame, market_price:pd.DataFrame,r_inf:float, current_date , period:period_selection):\n",
    "    \"\"\"Objective of this function is constructing a matrix with columns represent the simulation of a stock and row is number or stock\n",
    "\n",
    "    Args:\n",
    "        ticker (list): list of interested stock\n",
    "        cf_dict (dict): This dict store information of FCFF simulation of each stock\n",
    "        complementary (dict): This is stochastic complementary: wacc and value simulation,keys = [\"wacc\",\"value\"]\n",
    "        deterministic_complementary (pd.DataFrame): proportion of minority and net debt per share, it should be a multiindex data\n",
    "        market_price (pd.Dataframe): a vector represent the current market price of interested stock\n",
    "        r_inf (float): inflation rate\n",
    "        start_date (_type_): the current day\n",
    "        period (period_selection): annual or quarter\n",
    "    \"\"\"\n",
    "    market_price = market_price[ticker]\n",
    "    date = current_date - pd.offsets.MonthEnd()*(1-current_date.is_month_end)\n",
    "    latest_reported_date = current_date - pd.offsets.QuarterEnd()\n",
    "    deterministic_complementary = deterministic_complementary.xs(latest_reported_date,level='time')\n",
    "    price_vector = market_price.loc[date]\n",
    "    if period == \"annual\":\n",
    "        period_per_year = 1\n",
    "    elif period == \"quarter\":\n",
    "        period_per_year = 4\n",
    "    matrix = []\n",
    "    for i in ticker:\n",
    "        cf = cf_dict[i]\n",
    "        wacc = complementary[i]['wacc']\n",
    "        value = complementary[i]['value']\n",
    "        v_0 = value[:-1]\n",
    "        v_1 = value [1::]\n",
    "        minor_rate, net_debt = deterministic_complementary.loc[i].tolist()\n",
    "        price = price_vector.loc[i]*1000\n",
    "        r = projected_return(cf,wacc,v_0,v_1,r_inf/period_per_year,price,net_debt,minor_rate,period_per_year )\n",
    "        if len(matrix) == 0:\n",
    "            matrix = r\n",
    "        else:\n",
    "            matrix = np.column_stack([matrix,r])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e2730",
   "metadata": {},
   "source": [
    "<h3>6.2. Loi suat sinh loi cua tai san<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa109af",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = pd.to_datetime('2021-01-01')\n",
    "market_price = pd.read_csv('compare_data.csv')\n",
    "market_price['time'] = pd.to_datetime(market_price['time'])\n",
    "market_price.set_index('time',inplace=True)\n",
    "t = market_price.loc[['2021-01-04']]\n",
    "t.index = pd.to_datetime(['2020-12-31'])\n",
    "market_price = pd.concat([t,market_price])\n",
    "mp_data = market_price.resample('1M').last()\n",
    "\n",
    "ticker = list(mp_data.columns)\n",
    "tax_rate = 0.2\n",
    "r_inf = 0.03\n",
    "FCFF_dict, complementary = input_set_generate(ticker,generated_point,simulation_dict,current_date,tax_rate,annual_re_data,annual_estimated_cod)\n",
    "simulation_return = return_matrix_construction(ticker,FCFF_dict,complementary,deterministic_complementary,mp_data,r_inf,current_date,\"quarter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381664f7",
   "metadata": {},
   "source": [
    "<h2>7. Phan bo danh muc<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65e248",
   "metadata": {},
   "source": [
    "<h3>7.1. Cac ham can dung<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoR_calculation (r: np.ndarray, re:float):\n",
    "    \"\"\"calculating the risk measure(Cost of Risk-CoR)\n",
    "\n",
    "    Args:\n",
    "        r (np.ndarray): vector of return simulation\n",
    "        re (float): shareholder's required rate of return ve\n",
    "\n",
    "    Returns:\n",
    "        A real number\n",
    "    \"\"\"\n",
    "    L = re - r\n",
    "    positive_L = L*positive_condition(L)\n",
    "    return np.mean(positive_L)\n",
    "\n",
    "def objective_function_1 (theta:np.ndarray, return_matrix:np.ndarray, re_vector:np.ndarray, rf: float):\n",
    "    \"\"\"Function used to find the optimal weight\n",
    "\n",
    "    Args:\n",
    "        theta (np.ndarray): vector of [w,alpha]\n",
    "        return_matrix (np.ndarray): shape = (n, number of stock)\n",
    "        re_vector (np.ndarray): vector of re of each stock\n",
    "        rf (float): inflation rate\n",
    "\n",
    "    Returns:\n",
    "        a real number\n",
    "    \"\"\"\n",
    "    w = theta[:-1]\n",
    "    alpha = theta[-1]\n",
    "    re_p = re_vector.T@w\n",
    "    return_vector = return_matrix@w\n",
    "    Erp = np.mean(return_vector)\n",
    "    cor_p = CoR_calculation(return_vector,re_p)\n",
    "    first_term = alpha*np.log(Erp+1)\n",
    "    second_term = (1-alpha)*(np.log(1/(1-cor_p))-np.log(1+rf))\n",
    "    third_term = np.log(alpha)+np.log(1-alpha)\n",
    "    return -(first_term - second_term + third_term)\n",
    "\n",
    "def single_stock_utility (r:np.ndarray, re:float, rf:float ):\n",
    "    Er = np.mean(r)\n",
    "    cor = CoR_calculation(r,re)\n",
    "    t = np.log(Er+1)+np.log(1/(1-cor))-np.log(1+rf)\n",
    "    delta = (t-2)**2 + 4*t\n",
    "    a1 = ((2-t)-np.sqrt(delta))/(-2*t)\n",
    "    a2 = ((2-t)+np.sqrt(delta))/(-2*t)\n",
    "    alpha = max(a1,a2)\n",
    "    first_term = (Er+1)**alpha\n",
    "    second_term = ((1-cor)*(1+rf))**(1-alpha)\n",
    "    return first_term*second_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567433a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_markowitz ( weight:np.ndarray, matrix_return:np.ndarray):\n",
    "    covariance_matrix = np.cov(matrix_return,rowvar=False)\n",
    "    var = weight.T@covariance_matrix@weight\n",
    "    Er = np.mean(matrix_return@weight)\n",
    "    return - Er/np.sqrt(var)\n",
    "def markowitz_weight (matrix_return:np.ndarray):\n",
    "    init = np.full(shape=(matrix_return.shape[1],),fill_value=1)/matrix_return.shape[1]\n",
    "    bounds = [(0,1) for i in range(matrix_return.shape[1])]\n",
    "    constrains = {'type':'eq', 'fun': lambda w: np.sum(w)-1}\n",
    "    w = minimize(objective_function_markowitz,init, args=(matrix_return),bounds=bounds,constraints=constrains)\n",
    "    return w.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa083f1",
   "metadata": {},
   "source": [
    "<h3>7.3. Hold and forget strategy<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrains_func (theta):\n",
    "    return np.sum(theta[:-1]) -1\n",
    "constrains = {'type':'eq', 'fun':constrains_func}\n",
    "def theta_optimize (r_matrix:np.ndarray,re_vector:np.ndarray,rf:float,bounds: list):\n",
    "    init_theta = np.full(shape=(r_matrix.shape[1]+1,),fill_value=1)/(r_matrix.shape[1]+1)\n",
    "    w_opt = minimize(objective_function_1,init_theta,args=(r_matrix,re_vector,rf),bounds=bounds,\n",
    "                    constraints=constrains)\n",
    "    return w_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phan bo theo mo hinh\n",
    "bounds = [(0,1) for i in range(simulation_return.shape[1]+1)]\n",
    "re_vector = annual_re_data.loc[ticker].to_numpy()\n",
    "proposed_model_w = theta_optimize(simulation_return,re_vector,0.03,bounds)[:-1]\n",
    "#phan bo deu\n",
    "naive_w = np.full(shape=(simulation_return.shape[1]),fill_value=1)/simulation_return.shape[1]\n",
    "#markowitz\n",
    "markowitz_input = pd.read_csv('input_data.csv')\n",
    "markowitz_input['time'] = pd.to_datetime(markowitz_input['time'])\n",
    "markowitz_input.set_index('time',inplace=True)\n",
    "markowitz_input = markowitz_input[ticker][((markowitz_input.index.year>2015)&(markowitz_input.index.year<2021))]\n",
    "markowitz_input = np.log(markowitz_input/markowitz_input.shift())\n",
    "markowitz_input.dropna(inplace=True)\n",
    "markowitz_w = markowitz_weight(markowitz_input.to_numpy())\n",
    "#VNIndex\n",
    "vni = pd.read_csv('VNI_price.csv')\n",
    "vni['time'] = pd.to_datetime(vni['time'])\n",
    "vni.set_index('time',inplace=True)\n",
    "vni = vni[vni.index.year>2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82799bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 1e6\n",
    "ask_price = mp_data[ticker].iloc[0].to_numpy()\n",
    "\n",
    "proposed_model_postion = budget*proposed_model_w/ask_price\n",
    "naive_position = budget*naive_w/ask_price\n",
    "markowitz_position = budget*markowitz_w/ask_price\n",
    "vni_postion = budget/vni['vni'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_matrix = mp_data[ticker].to_numpy()\n",
    "proposed_wealth = compare_matrix@ proposed_model_postion\n",
    "naive_wealth = compare_matrix@naive_position\n",
    "markowitz_wealth = compare_matrix@markowitz_position\n",
    "vni_wealth = vni.to_numpy()*vni_postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ba35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(proposed_wealth,label='Proposed model 1 performance')\n",
    "plt.plot(markowitz_wealth,label = 'Markowitz_performance')\n",
    "plt.plot(naive_wealth,label=\"Naive performance\")\n",
    "plt.plot(vni_wealth, label='VNIndex performance')\n",
    "plt.title('Buy and Forget Strategy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8b624",
   "metadata": {},
   "source": [
    "<h3>7.4. Active management strategy<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad096b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_strategy_position (previous_weight: np.ndarray, current_weight: np.ndarray,current_mp: np.ndarray, transaction_fee_rate:float,cash_holding:float, stock_holding: float ):\n",
    "    \"\"\"To calculate the current position of portfolio\n",
    "\n",
    "    Args:\n",
    "        previous_weight (np.ndarray): The  proportion of each stock in portfolio in the previous period\n",
    "        current_weight (np.ndarray): The  proportion of each stock in the previous period\n",
    "        current_mp (np.ndarray): vector of current market price\n",
    "        transaction_fee_rate (float): the proportion of transaction value investor have pay to settle transactionn\n",
    "        cash_holding (float): value of cash investor hold\n",
    "        stock_holding (float): value of stock portfolio\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: a vector of postion of each stock\n",
    "    \"\"\"\n",
    "    w_diff = current_weight - previous_weight\n",
    "    sell_fee = -w_diff*negative_condition(w_diff)*stock_holding*transaction_fee_rate\n",
    "    sell_fee = np.sum(sell_fee)\n",
    "    \n",
    "    buy_fee = w_diff*positive_condition(w_diff)*(cash_holding+stock_holding)*transaction_fee_rate\n",
    "    buy_fee = np.sum(buy_fee)\n",
    "    transaction_fee = sell_fee + buy_fee\n",
    "    budget = stock_holding + cash_holding - transaction_fee\n",
    "    position = budget*current_weight/current_mp\n",
    "    return position\n",
    "def markowitz_input_function (raw_input:pd.DataFrame, current_date, number_of_month: float):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        raw_input (pd.DataFrame): matrix of stock price with row is sample size and columns is stock\n",
    "        current_date (_type_): \n",
    "        number_of_month (float): sample size\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: a matrix of stock log return\n",
    "    \"\"\"\n",
    "    start_date = current_date - pd.offsets.MonthEnd(number_of_month)\n",
    "    date_range =  pd.date_range(start=start_date,end=current_date,freq='1M')\n",
    "    marko_input = raw_input.loc[date_range]\n",
    "    marko_input = np.log(marko_input/marko_input.shift())\n",
    "    marko_input.dropna(inplace=True)\n",
    "    return marko_input.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb77557",
   "metadata": {},
   "outputs": [],
   "source": [
    "markowitz_input = pd.read_csv('input_data.csv')\n",
    "markowitz_input['time'] = pd.to_datetime(markowitz_input['time'])\n",
    "markowitz_input.set_index('time',inplace=True)\n",
    "markowitz_input = markowitz_input[ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(0,1) for i in range(simulation_return.shape[1]+1)]\n",
    "re_vector = annual_re_data.loc[ticker].to_numpy()\n",
    "fee_rate = 0.005\n",
    "rf = 0.03\n",
    "monthly_invested = 1e6\n",
    "initital_invest= 1e7\n",
    "previous_proposed_postition = np.full(shape=(simulation_return.shape[1]),fill_value=0)\n",
    "previous_proposed_weight = np.full(shape=(simulation_return.shape[1]),fill_value=0)\n",
    "proposed_port_value = []\n",
    "injected_capital = 0.00\n",
    "injected_capital_vector = []\n",
    "proposed_matrix_weight = []\n",
    "\n",
    "previous_markowitz_position = np.full(shape=(simulation_return.shape[1]),fill_value=0)\n",
    "previous_markowitz_weight = np.full(shape=(simulation_return.shape[1]),fill_value=0)\n",
    "markowitz_port_value = []\n",
    "marko_matrix_weigtht = []\n",
    "for date in mp_data.index[1::]:\n",
    "    cash = initital_invest+ monthly_invested\n",
    "    injected_capital += cash\n",
    "    injected_capital_vector.append(injected_capital)\n",
    "    mp = mp_data[ticker].loc[date].to_numpy()  \n",
    "    #Proposed Model\n",
    "    \n",
    "    stock_holding = previous_proposed_postition.T@mp\n",
    "    FCFF_dict, complementary = input_set_generate(ticker,generated_point,simulation_dict,date,tax_rate,annual_re_data,annual_estimated_cod)\n",
    "    simulation_return = return_matrix_construction(ticker,FCFF_dict,complementary,deterministic_complementary,mp_data,r_inf,date,\"quarter\")\n",
    "    proposed_w = theta_optimize(simulation_return,re_vector,rf,bounds)[:-1]\n",
    "    proposed_position = active_strategy_position(previous_proposed_weight,proposed_w,mp,fee_rate,cash,stock_holding)\n",
    "\n",
    "    previous_proposed_postition = proposed_position\n",
    "    previous_proposed_weight = proposed_w\n",
    "    #markowitz\n",
    "    markowitz_holding = previous_markowitz_position.T@mp\n",
    "    markowitz_matrix_input = markowitz_input_function(markowitz_input,date,60)\n",
    "    markowitz_w = markowitz_weight(markowitz_matrix_input)\n",
    "    markowitz_position = active_strategy_position(previous_markowitz_weight,markowitz_w,mp,fee_rate,cash,markowitz_holding)\n",
    "    \n",
    "    previous_markowitz_position = markowitz_position\n",
    "    previous_markowitz_weight = markowitz_w\n",
    "    if len(proposed_matrix_weight) == 0:\n",
    "        proposed_matrix_weight = proposed_w\n",
    "        marko_matrix_weigtht = markowitz_w\n",
    "    else:\n",
    "        proposed_matrix_weight = np.column_stack([proposed_matrix_weight, proposed_w])\n",
    "        marko_matrix_weigtht =  np.column_stack([marko_matrix_weigtht,markowitz_w])\n",
    "        \n",
    "    if len(markowitz_port_value) == 0:\n",
    "        markowitz_port_value.append(cash)\n",
    "        proposed_port_value.append(cash)\n",
    "    else:\n",
    "        markowitz_port_value.append(markowitz_holding)\n",
    "        proposed_port_value.append(stock_holding)\n",
    "    \n",
    "    initital_invest=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vni_position = []\n",
    "vni_pos = 0\n",
    "initital_invest = 1e7\n",
    "naive_pos = np.full(shape=(len(ticker),),fill_value=0.00)\n",
    "naive_position = []\n",
    "for date in vni.index:\n",
    "    cash = initital_invest + monthly_invested\n",
    "    cash = cash*(1- fee_rate)\n",
    "    vni_pos += cash / vni['vni'].loc[date]\n",
    "    naive_pos += cash*naive_w/mp_data.loc[date].to_numpy()\n",
    "    \n",
    "    vni_position.append(vni_pos)\n",
    "    if len(naive_position) == 0:\n",
    "        naive_position  = naive_pos\n",
    "    else:\n",
    "        naive_position  = np.column_stack([naive_position,naive_pos])\n",
    "    initital_invest = 0\n",
    "vni_position = np.array(vni_position)\n",
    "vni_port_value = vni_position*vni['vni'].to_numpy()\n",
    "naive_port_value = naive_position*mp_data.iloc[1::].transpose().to_numpy()\n",
    "naive_port_value = np.sum(naive_port_value,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80405ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(markowitz_port_value,label=\"Markowitz model\")\n",
    "plt.plot(proposed_port_value,label=\"Proposed model\")\n",
    "plt.plot(naive_port_value, label='Naive')\n",
    "plt.plot(vni_port_value,label=\"VNIndex\")\n",
    "plt.plot(injected_capital_vector, label=\"capital injected\")\n",
    "plt.title(\"Active Management strategy Performance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2026 (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
